{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from language_tool_python import LanguageTool\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Load LanguageTool for grammar checking\n",
    "grammar_tool = LanguageTool('en-US')\n",
    "\n",
    "def calculate_grammar_score(essay):\n",
    "\n",
    "    # Check grammar\n",
    "    matches = grammar_tool.check(essay)\n",
    "\n",
    "    # Calculate grammar score out of 10\n",
    "    max_score = 10\n",
    "    grammar_score = max_score - len(matches)\n",
    "    \n",
    "    # Ensure the score is within the valid range\n",
    "    grammar_score = max(0, min(max_score, grammar_score))\n",
    "    if grammar_score == 0:\n",
    "        grammar_score=grammar_score+2\n",
    "    return round(grammar_score,1)\n",
    "    \n",
    "\n",
    "def calculate_spelling_score(essay):\n",
    "    spell = SpellChecker()\n",
    "    words = essay.split()\n",
    "    misspelled = spell.unknown(words)\n",
    "    \n",
    "    # Get the raw spelling score\n",
    "    raw_score = len(misspelled)\n",
    "    \n",
    "    # Define the mapping between original range and desired range\n",
    "    original_range = (0, 30)  # Adjust this based on your expected range of misspelled words\n",
    "    desired_range = (10, 1)   # Reverse the order to get higher scores for fewer mistakes\n",
    "    \n",
    "    # Scale the raw score to the desired range\n",
    "    scaled_score = (raw_score - original_range[0]) / (original_range[1] - original_range[0]) \\\n",
    "                   * (desired_range[1] - desired_range[0]) + desired_range[0]\n",
    "    \n",
    "    # Ensure the scaled score is within the desired range\n",
    "    scaled_score = max(min(scaled_score, max(desired_range)), min(desired_range))\n",
    "    \n",
    "    return round(scaled_score,1)\n",
    "\n",
    "def calculate_word_diversity(essay):\n",
    "    # Tokenize the essay into words\n",
    "    words = essay.split()\n",
    "\n",
    "    # Calculate the number of unique words\n",
    "    unique_words = set(words)\n",
    "    num_unique_words = len(unique_words)\n",
    "\n",
    "    # Calculate the word diversity score (ratio of unique words to total words)\n",
    "    word_diversity_score = num_unique_words / len(words) if len(words) > 0 else 0\n",
    "\n",
    "    # Scale the score to be out of 10\n",
    "    scaled_word_diversity_score = word_diversity_score * 10\n",
    "\n",
    "    return round(min(scaled_word_diversity_score, 10),1)\n",
    "def grade_essay(essay):\n",
    "    # Tokenize and encode the essay using BERT tokenizer\n",
    "    inputs = tokenizer(essay, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    # Get the BERT model prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Assuming the model predicts a score in the range [0, 1] for essay quality\n",
    "    # Assuming the model predicts scores for multiple classes\n",
    "    class_probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # You may want to use the class with the highest probability as your essay quality score\n",
    "    predicted_class = torch.argmax(class_probabilities, dim=1)\n",
    "\n",
    "    # Assuming your scores are in the range [0, 1]\n",
    "    essay_quality_score = class_probabilities[0, predicted_class].item() * 10\n",
    "\n",
    "    # essay_quality_score = outputs.logits.item() * 10  # Scale to a score out of 10\n",
    "    \n",
    "    # Calculate scores for each parameter\n",
    "    grammar_score = calculate_grammar_score(essay)\n",
    "    spelling_score = calculate_spelling_score(essay)\n",
    "    word_diversity_score = calculate_word_diversity(essay)\n",
    "    print(grammar_score)\n",
    "    print(spelling_score)\n",
    "    print(word_diversity_score)\n",
    "    print(essay_quality_score)\n",
    "    # Combine scores and return the final grade\n",
    "    total_score = (grammar_score + spelling_score + word_diversity_score) / 3\n",
    "    return round(essay_quality_score,1)\n",
    "\n",
    "# Example usage\n",
    "# essay_to_grade = \"Population explosion is one of the most serious problems in the world. Therefore a rule was promulgated to limit the number of children a family can have. In my opinion,it obeys basic human rights,some people really like children and they have financial to bring them up. They should have as many children as they like. Besides,only one child in a family causes some problems.The children always feel lonely,meanwhile parents often give them too much love,which lead them have some bad habits,just like selfish. Some people think population explosion bring some problems.It may increase the earth burden,we need more food to feed people,we need more water,more resources.However,I believe people have enough able to solve those problems. Considering the future of our children,limit the number of children is unwise.\"\n",
    "# grade = grade_essay(essay_to_grade)\n",
    "# print(f\"Grade for the essay: {grade}/10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "6.5\n",
      "6.476115584373474\n",
      "4\n",
      "5.5\n",
      "6.2\n",
      "6.446475982666016\n",
      "1\n",
      "2.5\n",
      "5.6\n",
      "6.431941390037537\n",
      "3\n",
      "4.9\n",
      "6.4\n",
      "6.30523681640625\n",
      "10\n",
      "3.4\n",
      "6.1\n",
      "6.505116820335388\n",
      "2\n",
      "4.0\n",
      "7.0\n",
      "6.505624055862427\n",
      "8\n",
      "5.5\n",
      "5.6\n",
      "6.666485667228699\n",
      "2\n",
      "2.8\n",
      "2.0\n",
      "7.266813516616821\n",
      "5\n",
      "1\n",
      "6.6\n",
      "6.286317706108093\n",
      "9\n",
      "1.6\n",
      "7.0\n",
      "6.105132699012756\n",
      "6\n",
      "2.5\n",
      "6.7\n",
      "6.51044487953186\n",
      "10\n",
      "5.2\n",
      "6.3\n",
      "6.659994721412659\n",
      "8\n",
      "4.6\n",
      "6.9\n",
      "6.248441934585571\n",
      "7\n",
      "6.4\n",
      "6.1\n",
      "6.366661787033081\n",
      "6\n",
      "3.4\n",
      "6.8\n",
      "6.418891549110413\n",
      "9\n",
      "3.1\n",
      "6.4\n",
      "6.324787139892578\n",
      "4\n",
      "4.0\n",
      "6.9\n",
      "6.452975869178772\n",
      "6\n",
      "4.3\n",
      "6.7\n",
      "6.560290455818176\n",
      "9\n",
      "4.9\n",
      "6.1\n",
      "6.579070091247559\n",
      "3\n",
      "1.3\n",
      "6.5\n",
      "6.411119103431702\n",
      "6\n",
      "5.2\n",
      "6.1\n",
      "6.567816138267517\n",
      "5\n",
      "5.5\n",
      "6.6\n",
      "6.373659372329712\n",
      "2\n",
      "1\n",
      "6.8\n",
      "6.337913274765015\n",
      "3\n",
      "5.2\n",
      "7.2\n",
      "6.56893253326416\n",
      "7\n",
      "5.8\n",
      "7.4\n",
      "6.619383692741394\n",
      "9\n",
      "3.7\n",
      "6.5\n",
      "6.54568076133728\n",
      "9\n",
      "5.8\n",
      "6.6\n",
      "6.281826496124268\n",
      "2\n",
      "2.2\n",
      "7.1\n",
      "6.327542662620544\n",
      "8\n",
      "4.0\n",
      "6.5\n",
      "6.560951471328735\n",
      "10\n",
      "4.6\n",
      "6.4\n",
      "6.34128212928772\n",
      "2\n",
      "6.7\n",
      "5.0\n",
      "6.503906846046448\n",
      "9\n",
      "5.8\n",
      "5.1\n",
      "6.503797173500061\n",
      "5\n",
      "1.9\n",
      "6.0\n",
      "6.415253281593323\n",
      "2\n",
      "4.6\n",
      "6.8\n",
      "6.311817169189453\n",
      "2\n",
      "5.5\n",
      "7.6\n",
      "6.292164325714111\n",
      "5\n",
      "4.9\n",
      "5.9\n",
      "6.586505770683289\n",
      "8\n",
      "5.5\n",
      "7.1\n",
      "6.30531370639801\n",
      "2\n",
      "4.0\n",
      "5.0\n",
      "6.0295528173446655\n",
      "6\n",
      "3.7\n",
      "5.5\n",
      "6.865702271461487\n",
      "6\n",
      "4.3\n",
      "7.1\n",
      "6.77112877368927\n",
      "9\n",
      "1\n",
      "6.1\n",
      "6.619463562965393\n",
      "8\n",
      "3.7\n",
      "6.6\n",
      "6.544051766395569\n",
      "6\n",
      "4.9\n",
      "6.9\n",
      "6.361208558082581\n",
      "5\n",
      "4.3\n",
      "6.7\n",
      "6.337334513664246\n",
      "9\n",
      "4.0\n",
      "6.1\n",
      "6.093316078186035\n",
      "7\n",
      "2.2\n",
      "6.6\n",
      "6.785098910331726\n",
      "2\n",
      "4.0\n",
      "6.0\n",
      "6.422848701477051\n",
      "9\n",
      "5.8\n",
      "6.7\n",
      "6.3632553815841675\n",
      "5\n",
      "4.0\n",
      "6.1\n",
      "6.52926504611969\n",
      "6\n",
      "2.2\n",
      "6.5\n",
      "6.283419728279114\n",
      "2\n",
      "3.7\n",
      "6.1\n",
      "6.378732323646545\n",
      "2\n",
      "1.0\n",
      "7.3\n",
      "6.439868807792664\n",
      "2\n",
      "1\n",
      "6.7\n",
      "6.311781406402588\n",
      "9\n",
      "4.9\n",
      "6.2\n",
      "6.4177244901657104\n",
      "1\n",
      "3.4\n",
      "6.3\n",
      "6.58890426158905\n",
      "2\n",
      "1\n",
      "5.7\n",
      "6.541539430618286\n",
      "4\n",
      "4.9\n",
      "7.0\n",
      "6.621838808059692\n",
      "6\n",
      "5.2\n",
      "6.6\n",
      "6.51763916015625\n",
      "5\n",
      "1.9\n",
      "5.8\n",
      "6.293182969093323\n",
      "6\n",
      "2.5\n",
      "5.4\n",
      "6.34630560874939\n",
      "10\n",
      "5.5\n",
      "4.9\n",
      "6.537459492683411\n",
      "7\n",
      "1\n",
      "6.3\n",
      "6.234174966812134\n",
      "2\n",
      "3.1\n",
      "5.8\n",
      "6.420995593070984\n",
      "8\n",
      "3.1\n",
      "6.8\n",
      "6.505698561668396\n",
      "6\n",
      "2.2\n",
      "5.8\n",
      "6.526162624359131\n",
      "2\n",
      "1.3\n",
      "5.9\n",
      "6.4191752672195435\n",
      "6\n",
      "1\n",
      "6.7\n",
      "6.107161045074463\n",
      "10\n",
      "1\n",
      "6.3\n",
      "6.219165325164795\n",
      "7\n",
      "1\n",
      "5.7\n",
      "6.5255361795425415\n",
      "2\n",
      "1\n",
      "5.4\n",
      "6.309545636177063\n",
      "7\n",
      "1.6\n",
      "5.2\n",
      "6.513124108314514\n",
      "4\n",
      "1\n",
      "5.4\n",
      "6.465586423873901\n",
      "2\n",
      "2.2\n",
      "5.4\n",
      "6.5182071924209595\n",
      "7\n",
      "4.0\n",
      "5.6\n",
      "6.485810875892639\n",
      "6\n",
      "1\n",
      "5.8\n",
      "6.6652607917785645\n",
      "5\n",
      "3.1\n",
      "5.8\n",
      "6.319581866264343\n",
      "6\n",
      "1\n",
      "6.2\n",
      "6.220898628234863\n",
      "2\n",
      "2.8\n",
      "5.7\n",
      "6.508910059928894\n",
      "7\n",
      "1\n",
      "6.5\n",
      "6.336100697517395\n",
      "8\n",
      "1.0\n",
      "4.9\n",
      "6.446390748023987\n",
      "4\n",
      "1\n",
      "5.1\n",
      "6.362864375114441\n",
      "2\n",
      "1\n",
      "6.2\n",
      "6.04674756526947\n",
      "8\n",
      "1\n",
      "5.4\n",
      "6.805016398429871\n",
      "7\n",
      "1\n",
      "6.3\n",
      "6.09950065612793\n",
      "2\n",
      "1\n",
      "5.6\n",
      "6.261900067329407\n",
      "2\n",
      "1\n",
      "5.3\n",
      "6.4588212966918945\n",
      "2\n",
      "1\n",
      "5.7\n",
      "6.2470316886901855\n",
      "2\n",
      "1\n",
      "5.9\n",
      "6.334502696990967\n",
      "2\n",
      "1\n",
      "6.1\n",
      "6.263903379440308\n",
      "9\n",
      "1.9\n",
      "5.1\n",
      "6.5191638469696045\n",
      "5\n",
      "1\n",
      "6.1\n",
      "6.350330114364624\n",
      "2\n",
      "1\n",
      "4.5\n",
      "6.399741172790527\n",
      "6\n",
      "1\n",
      "5.5\n",
      "6.465774774551392\n",
      "2\n",
      "1\n",
      "5.8\n",
      "6.632856130599976\n",
      "9\n",
      "1.6\n",
      "5.7\n",
      "6.065720915794373\n",
      "6\n",
      "1.0\n",
      "6.5\n",
      "6.374279856681824\n",
      "9\n",
      "3.1\n",
      "5.8\n",
      "6.201214790344238\n",
      "6\n",
      "1\n",
      "5.8\n",
      "6.687522530555725\n",
      "2\n",
      "3.4\n",
      "6.2\n",
      "6.340086460113525\n",
      "2\n",
      "1\n",
      "5.8\n",
      "6.227107048034668\n",
      "6\n",
      "1\n",
      "6.1\n",
      "6.428192853927612\n",
      "3\n",
      "1\n",
      "6.4\n",
      "6.296656131744385\n",
      "6\n",
      "1.9\n",
      "5.7\n",
      "6.68775200843811\n",
      "7\n",
      "1\n",
      "5.3\n",
      "6.500928997993469\n",
      "10\n",
      "1\n",
      "5.7\n",
      "6.442820429801941\n",
      "2\n",
      "1\n",
      "5.9\n",
      "6.306159496307373\n",
      "2\n",
      "3.1\n",
      "5.7\n",
      "6.534687280654907\n",
      "2\n",
      "1\n",
      "5.4\n",
      "6.44625186920166\n",
      "4\n",
      "1\n",
      "5.8\n",
      "6.436734199523926\n",
      "2\n",
      "1\n",
      "5.9\n",
      "6.3222938776016235\n",
      "9\n",
      "1\n",
      "6.1\n",
      "6.53128981590271\n",
      "8\n",
      "1.9\n",
      "5.4\n",
      "6.372268795967102\n",
      "2\n",
      "1\n",
      "6.2\n",
      "6.572015881538391\n",
      "7\n",
      "3.1\n",
      "5.0\n",
      "6.537332534790039\n",
      "2\n",
      "1.0\n",
      "5.6\n",
      "6.6202181577682495\n",
      "2\n",
      "1\n",
      "6.2\n",
      "6.349146366119385\n",
      "1\n",
      "1\n",
      "6.2\n",
      "6.032901406288147\n",
      "2\n",
      "1\n",
      "5.9\n",
      "6.802690029144287\n",
      "2\n",
      "1.6\n",
      "5.9\n",
      "6.304078102111816\n",
      "8\n",
      "1\n",
      "5.9\n",
      "6.467038989067078\n",
      "7\n",
      "1.0\n",
      "5.4\n",
      "6.330047845840454\n",
      "2\n",
      "1\n",
      "5.4\n",
      "6.169673800468445\n",
      "6\n",
      "1\n",
      "6.1\n",
      "6.348112225532532\n",
      "8\n",
      "1\n",
      "6.6\n",
      "6.389208436012268\n",
      "9\n",
      "1\n",
      "6.0\n",
      "6.48965060710907\n",
      "7\n",
      "1.3\n",
      "6.4\n",
      "6.278514862060547\n",
      "10\n",
      "1.9\n",
      "5.1\n",
      "6.504034399986267\n",
      "3\n",
      "1\n",
      "5.8\n",
      "6.615735292434692\n",
      "7\n",
      "1\n",
      "6.1\n",
      "6.517878174781799\n",
      "2\n",
      "1\n",
      "6.3\n",
      "6.308097839355469\n",
      "8\n",
      "2.2\n",
      "6.0\n",
      "6.4386433362960815\n",
      "8\n",
      "1\n",
      "5.2\n",
      "6.7181700468063354\n",
      "10\n",
      "1\n",
      "6.7\n",
      "6.496068239212036\n",
      "4\n",
      "1\n",
      "5.7\n",
      "6.341003179550171\n",
      "5\n",
      "1.3\n",
      "5.9\n",
      "6.596512198448181\n",
      "8\n",
      "2.8\n",
      "5.8\n",
      "6.221851706504822\n",
      "2\n",
      "2.8\n",
      "5.1\n",
      "6.259928941726685\n",
      "7\n",
      "1\n",
      "5.7\n",
      "6.243914365768433\n",
      "4\n",
      "1\n",
      "5.3\n",
      "6.595955491065979\n",
      "7\n",
      "1\n",
      "5.5\n",
      "6.403107643127441\n",
      "3\n",
      "1.3\n",
      "5.6\n",
      "6.389409303665161\n",
      "2\n",
      "1\n",
      "5.8\n",
      "6.0638415813446045\n",
      "2\n",
      "1\n",
      "5.8\n",
      "6.007180213928223\n",
      "8\n",
      "1\n",
      "6.2\n",
      "6.369200348854065\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read essays from the CSV file\n",
    "essays_df = pd.read_csv('model2.csv')\n",
    "\n",
    "# Function to calculate scores and update the DataFrame\n",
    "def calculate_scores_and_update_df(df):\n",
    "    # Iterate over each row (essay)\n",
    "    for index, row in df.iterrows():\n",
    "        essay = row['Essays']  # Assuming 'essay' is the column name containing the essays\n",
    "        # Calculate scores\n",
    "        grammar_score = calculate_grammar_score(essay)\n",
    "        spelling_score = calculate_spelling_score(essay)\n",
    "        word_diversity_score = calculate_word_diversity(essay)\n",
    "        essay_quality_score = grade_essay(essay)\n",
    "        # Update DataFrame with scores\n",
    "        df.at[index, 'Grammar Score'] = grammar_score\n",
    "        df.at[index, 'Spelling Score'] = spelling_score\n",
    "        df.at[index, 'Word Diversity Score'] = word_diversity_score\n",
    "        df.at[index, 'Essay Quality Score'] = essay_quality_score\n",
    "\n",
    "# Apply scoring function and update the DataFrame\n",
    "calculate_scores_and_update_df(essays_df)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "essays_df.to_csv('model2_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 22.195011138916016\n",
      "Epoch 1, Mean Squared Error: 22.195011138916016\n",
      "Mean Squared Error: 17.267799377441406\n",
      "Epoch 2, Mean Squared Error: 17.267799377441406\n",
      "Mean Squared Error: 13.254861831665039\n",
      "Epoch 3, Mean Squared Error: 13.254861831665039\n",
      "Mean Squared Error: 10.613543510437012\n",
      "Epoch 4, Mean Squared Error: 10.613543510437012\n",
      "Mean Squared Error: 8.51755142211914\n",
      "Epoch 5, Mean Squared Error: 8.51755142211914\n",
      "Mean Squared Error: 6.853306770324707\n",
      "Epoch 6, Mean Squared Error: 6.853306770324707\n",
      "Mean Squared Error: 5.536619186401367\n",
      "Epoch 7, Mean Squared Error: 5.536619186401367\n",
      "Mean Squared Error: 4.5372724533081055\n",
      "Epoch 8, Mean Squared Error: 4.5372724533081055\n",
      "Mean Squared Error: 3.8529245853424072\n",
      "Epoch 9, Mean Squared Error: 3.8529245853424072\n",
      "Mean Squared Error: 3.4523301124572754\n",
      "Epoch 10, Mean Squared Error: 3.4523301124572754\n",
      "Mean Squared Error: 3.308626890182495\n",
      "Epoch 11, Mean Squared Error: 3.308626890182495\n",
      "Mean Squared Error: 3.35064435005188\n",
      "Epoch 12, Mean Squared Error: 3.35064435005188\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/siddh/Desktop/BERT/New folder/model2_final.csv\")\n",
    "\n",
    "# Extract essay texts and labels\n",
    "essays = df['Essays'].tolist()\n",
    "labels = df[['Grammar Score','Spelling Score','Word Diversity Score','Essay Quality Score']].values\n",
    "\n",
    "# Tokenization function\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokens['input_ids'], tokens['attention_mask']\n",
    "\n",
    "# Prepare data function\n",
    "def prepare_data(texts, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        tokens = tokenize_text(text)\n",
    "        input_ids.append(tokens[0])\n",
    "        attention_masks.append(tokens[1])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)  # Ensure labels are of the correct type\n",
    "\n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(essays, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the BERT model for regression on each target\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Prepare the training data\n",
    "input_ids, attention_masks, labels = prepare_data(essays, labels)\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Prepare the validation data\n",
    "val_input_ids, val_attention_masks, val_labels = prepare_data(val_texts, val_labels)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            all_preds.extend(logits.cpu().numpy())\n",
    "            all_labels.extend(batch[2].cpu().numpy())\n",
    "        mse = mean_squared_error(all_labels, all_preds)\n",
    "        print(f'Mean Squared Error: {mse}')\n",
    "    return mse\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 12\n",
    "best_val_loss = float('inf')  # Initialize with a large value for comparison\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    val_loss = evaluate_model(model, val_dataloader)\n",
    "\n",
    "    # Print or log the learning rate if desired\n",
    "    print(f'Epoch {epoch + 1}, Mean Squared Error: {val_loss}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_save_path = f\"essay_scoring_model_regression_{timestamp}\"\n",
    "        model.save_pretrained(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.600276  2.621825  6.5486956 5.6218677]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokens['input_ids'], tokens['attention_mask']\n",
    "\n",
    "\n",
    "def prepare_data(texts, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        tokens = tokenize_text(text)\n",
    "        input_ids.append(tokens[0])\n",
    "        attention_masks.append(tokens[1])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)  # Ensure labels are of the correct type\n",
    "\n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"C:\\\\Users\\\\siddh\\\\Desktop\\\\BERT\\\\New folder\\\\essay_scoring_model_regression_20240229_133324\"  # Replace <timestamp> with the actual timestamp\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Tokenize the input essays\n",
    "input_essays = [\"With the development of our city, human right is talked by everyone of us more and more often, and for the city, two kids allowed to be born, is another stone throw into the lake, and that means the number of people will get a new chance to up to a amazing point, by the way, can we ask us a simple question: what are we going to sacrifice again to tell what's right or what's wrong with us. we only see high speed grow up of our city, but we never see the cut down tree, the populated watered, we can not put up a banner on a lonely tree surrounded by stumps, the go up number of people will lead to many problem, which many person think is the outstanding of human right. It's not what we say but what we that matters, we can't bring the whole world into mad then thinking what we could do to save it.\"]\n",
    "\n",
    "# Prepare input tensors\n",
    "input_ids, attention_masks, _ = prepare_data(input_essays, [])\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = {'input_ids': input_ids, 'attention_mask': attention_masks}\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = logits.cpu().numpy()\n",
    "\n",
    "# Post-process the predictions if necessary\n",
    "# For example, if you want to get the final predicted scores for each aspect:\n",
    "predicted_scores = predictions.squeeze()  # Squeeze removes the extra dimension added by batch processing\n",
    "\n",
    "# Now predicted_scores contains the predicted scores for each aspect\n",
    "print(predicted_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
